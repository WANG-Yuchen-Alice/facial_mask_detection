{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import random\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cpu\") #cuda\n",
    "print(device)\n",
    "\n",
    "root_dir = os.getcwd() + '/data_processing'\n",
    "\n",
    "train_dir = root_dir + '/train_set/'\n",
    "val_dir = root_dir + '/val_set/'\n",
    "test_dir = root_dir + '/test_set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.getcwd() + '/model_CNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceSet(data.Dataset):\n",
    "    def __init__(self,folder,labels,transform):\n",
    "        self.labels = labels\n",
    "        self.transform=transform\n",
    "        imgs=[os.path.join(folder,f) for f in os.listdir(folder)]\n",
    "        self.imgs = imgs\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        imgpath=self.imgs[index]\n",
    "        im=Image.open(imgpath)\n",
    "        if im.mode == \"RGBA\":\n",
    "            r, g, b, a=im.split ()\n",
    "            im=Image.merge (\"RGB\", (r, g, b))\n",
    "        elif im.mode!=\"RGB\":\n",
    "            im=im.convert (\"RGB\")\n",
    "        im=self.transform(im)\n",
    "        label = self.labels[index]\n",
    "        return im,label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "imgsize=64\n",
    "transform_train=transforms.Compose([ \n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomCrop((imgsize,imgsize)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test=transforms.Compose([ \n",
    "    transforms.Resize((imgsize,imgsize)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "for fn in os.listdir(train_dir):\n",
    "    im=Image.open(train_dir + fn)\n",
    "    print(transform_train(im).size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.load(root_dir + '/train_labels.pt')\n",
    "test_labels = torch.load(root_dir + '/test_labels.pt')\n",
    "val_labels = torch.load(root_dir + '/val_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "trainset=FaceSet(train_dir,train_labels,transform=transform_train)\n",
    "valset=FaceSet(val_dir,val_labels,transform=transform_test)\n",
    "testset=FaceSet(test_dir,test_labels,transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        # 3 x 64 x 64 -> 64 x 32 x 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1 ),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 64 x 32 x 32 -> 128 x 16 x 16\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1 ),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 128 x 16 x 16 -> 256 x 8 x 8\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1 ),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 256 x 8 x 8 -> 512 x 4 x 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1 ),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(8192, 512)\n",
    "        self.linear2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = x.view(-1, 8192)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "def get_error( scores , labels ):\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches=indicator.sum()\n",
    "    \n",
    "    return 1-num_matches.float()/bs  \n",
    "\n",
    "def eval_on_test_set(loader):\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    for batch_idx,(img,label) in enumerate(loader):\n",
    "        img=img\n",
    "        img=img.to(device)\n",
    "        scores=net(img) \n",
    "        label=label.to(device) \n",
    "        error = get_error( scores , label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'test error  = ', total_error*100 ,'percent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnn()\n",
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "bs = 10\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=bs,shuffle=True,num_workers=0)\n",
    "valloader=torch.utils.data.DataLoader(valset,batch_size=bs,shuffle=False,num_workers=0)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=bs,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "before\n",
      "None tensor([[[[-0.0246, -0.1740,  0.0036],\n",
      "          [-0.0339, -0.0967, -0.1110],\n",
      "          [-0.1240, -0.1803,  0.0393]],\n",
      "\n",
      "         [[-0.0360,  0.0760,  0.1860],\n",
      "          [-0.1812, -0.0275,  0.0535],\n",
      "          [-0.1886, -0.0501, -0.0741]],\n",
      "\n",
      "         [[-0.0908, -0.1469, -0.0490],\n",
      "          [-0.0054, -0.0565,  0.0363],\n",
      "          [ 0.1269, -0.0756, -0.0654]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0171, -0.1361, -0.1221],\n",
      "          [ 0.0828,  0.1699,  0.0022],\n",
      "          [ 0.0162,  0.0744,  0.1060]],\n",
      "\n",
      "         [[ 0.0285,  0.1253, -0.1256],\n",
      "          [ 0.0264, -0.0877, -0.0615],\n",
      "          [-0.1132,  0.1196,  0.1880]],\n",
      "\n",
      "         [[-0.0448, -0.1337, -0.0800],\n",
      "          [-0.1609,  0.0888,  0.1584],\n",
      "          [-0.0826,  0.1668,  0.1280]]],\n",
      "\n",
      "\n",
      "        [[[-0.1034, -0.1555, -0.0420],\n",
      "          [-0.0130,  0.0362, -0.0055],\n",
      "          [ 0.0965, -0.0408, -0.0849]],\n",
      "\n",
      "         [[ 0.1129,  0.1828,  0.1702],\n",
      "          [ 0.0382, -0.0462,  0.1378],\n",
      "          [ 0.0058, -0.0526, -0.1743]],\n",
      "\n",
      "         [[-0.0379, -0.1719,  0.1748],\n",
      "          [ 0.1207, -0.0164,  0.0986],\n",
      "          [ 0.0632, -0.0331,  0.0088]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0101, -0.0618, -0.0919],\n",
      "          [ 0.1545, -0.1168,  0.0384],\n",
      "          [ 0.0175, -0.1178,  0.0373]],\n",
      "\n",
      "         [[ 0.0562,  0.1823,  0.1279],\n",
      "          [-0.1227, -0.1535,  0.0859],\n",
      "          [ 0.0222,  0.0800,  0.1605]],\n",
      "\n",
      "         [[-0.0804,  0.1618, -0.1308],\n",
      "          [ 0.0620, -0.0274, -0.0254],\n",
      "          [ 0.1789,  0.1769, -0.0834]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1799,  0.1110,  0.1748],\n",
      "          [-0.0155,  0.0476, -0.0677],\n",
      "          [-0.1887,  0.1392,  0.0673]],\n",
      "\n",
      "         [[-0.0960,  0.1098,  0.1004],\n",
      "          [-0.0564, -0.0645, -0.0620],\n",
      "          [ 0.1470, -0.0278,  0.1411]],\n",
      "\n",
      "         [[ 0.0985,  0.0935,  0.1284],\n",
      "          [-0.1646,  0.1794, -0.0329],\n",
      "          [-0.0157,  0.0501, -0.1762]]],\n",
      "\n",
      "\n",
      "        [[[-0.1869, -0.0627, -0.1525],\n",
      "          [ 0.0148, -0.1246,  0.0003],\n",
      "          [-0.0060, -0.0043,  0.0415]],\n",
      "\n",
      "         [[-0.1748,  0.0639, -0.0733],\n",
      "          [ 0.0024, -0.0660, -0.1272],\n",
      "          [-0.0548,  0.1242, -0.1124]],\n",
      "\n",
      "         [[ 0.0309, -0.1235,  0.1797],\n",
      "          [ 0.1519, -0.1520, -0.1517],\n",
      "          [ 0.1275, -0.0435,  0.1671]]]])\n",
      "after\n",
      "None tensor([[[[ 0.0754, -0.0740,  0.1036],\n",
      "          [-0.1339,  0.0033, -0.0110],\n",
      "          [-0.0240, -0.0803,  0.1393]],\n",
      "\n",
      "         [[-0.1360, -0.0240,  0.2860],\n",
      "          [-0.2812, -0.1275,  0.1535],\n",
      "          [-0.2886, -0.1501,  0.0259]],\n",
      "\n",
      "         [[-0.1908, -0.2469, -0.1490],\n",
      "          [-0.1054, -0.1565, -0.0637],\n",
      "          [ 0.0269, -0.1756,  0.0346]]],\n",
      "\n",
      "\n",
      "        [[[-0.0829, -0.2361, -0.2221],\n",
      "          [-0.0172,  0.0699, -0.0978],\n",
      "          [-0.0838, -0.0256,  0.0060]],\n",
      "\n",
      "         [[-0.0715,  0.0253, -0.2256],\n",
      "          [-0.0736, -0.1877, -0.1615],\n",
      "          [-0.2132,  0.0196,  0.0880]],\n",
      "\n",
      "         [[-0.1448, -0.2337, -0.1800],\n",
      "          [-0.2609, -0.0112,  0.0584],\n",
      "          [-0.1826,  0.0668,  0.0280]]],\n",
      "\n",
      "\n",
      "        [[[-0.0034, -0.0555,  0.0580],\n",
      "          [ 0.0870,  0.1362,  0.0945],\n",
      "          [ 0.1965,  0.0592,  0.0151]],\n",
      "\n",
      "         [[ 0.2129,  0.2828,  0.2702],\n",
      "          [ 0.1382,  0.0538,  0.2378],\n",
      "          [ 0.1058,  0.0474, -0.0743]],\n",
      "\n",
      "         [[-0.1379, -0.2719,  0.0748],\n",
      "          [ 0.0207, -0.1164, -0.0014],\n",
      "          [-0.0368, -0.1331,  0.1088]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0899, -0.1618,  0.0081],\n",
      "          [ 0.0545, -0.0168,  0.1384],\n",
      "          [-0.0825, -0.0178,  0.1373]],\n",
      "\n",
      "         [[-0.0438,  0.0823,  0.2279],\n",
      "          [-0.2227, -0.0535,  0.1859],\n",
      "          [-0.0778,  0.1800,  0.2605]],\n",
      "\n",
      "         [[-0.1803,  0.2618, -0.0308],\n",
      "          [ 0.1620,  0.0726,  0.0746],\n",
      "          [ 0.2789,  0.2769,  0.0166]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0799,  0.0110,  0.0748],\n",
      "          [-0.1155, -0.0524, -0.1677],\n",
      "          [-0.2887,  0.2392,  0.1673]],\n",
      "\n",
      "         [[ 0.0040,  0.2098,  0.0004],\n",
      "          [-0.1563,  0.0355, -0.1620],\n",
      "          [ 0.0470,  0.0722,  0.2411]],\n",
      "\n",
      "         [[-0.0015, -0.0065,  0.0284],\n",
      "          [-0.2646,  0.0794, -0.1329],\n",
      "          [-0.1157,  0.1501, -0.0762]]],\n",
      "\n",
      "\n",
      "        [[[-0.0869,  0.0373, -0.0525],\n",
      "          [ 0.1148, -0.0246,  0.1002],\n",
      "          [ 0.0940,  0.0957,  0.1415]],\n",
      "\n",
      "         [[-0.0748,  0.1639,  0.0267],\n",
      "          [ 0.1024,  0.0340, -0.0272],\n",
      "          [ 0.0452,  0.2242, -0.0124]],\n",
      "\n",
      "         [[ 0.1309, -0.0235,  0.2797],\n",
      "          [ 0.2519, -0.0520, -0.0517],\n",
      "          [ 0.2275,  0.0565,  0.2671]]]])\n",
      "> \u001b[0;32m<ipython-input-13-5e72715dc89b>\u001b[0m(15)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m    \u001b[0mrunning_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> scores.detach()\n",
      "tensor([[ 0.0250,  0.2284],\n",
      "        [-0.0302,  0.2341],\n",
      "        [-0.0514,  0.3538],\n",
      "        [ 0.1790,  0.3700],\n",
      "        [ 0.0589,  0.2310],\n",
      "        [-0.0284,  0.2145],\n",
      "        [-0.0302,  0.0801],\n",
      "        [-0.2029,  0.1653],\n",
      "        [ 0.1461,  0.1393],\n",
      "        [ 0.0221,  0.2808]])\n",
      "ipdb> scores\n",
      "tensor([[ 0.0250,  0.2284],\n",
      "        [-0.0302,  0.2341],\n",
      "        [-0.0514,  0.3538],\n",
      "        [ 0.1790,  0.3700],\n",
      "        [ 0.0589,  0.2310],\n",
      "        [-0.0284,  0.2145],\n",
      "        [-0.0302,  0.0801],\n",
      "        [-0.2029,  0.1653],\n",
      "        [ 0.1461,  0.1393],\n",
      "        [ 0.0221,  0.2808]], grad_fn=<AddmmBackward0>)\n",
      "ipdb> label\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5e72715dc89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrunning_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5e72715dc89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrunning_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "#     if epoch % 10 == 0 and epoch > 10: \n",
    "#         lr = lr / 1.5\n",
    "# #     if epoch == 10 or epoch == 14 or epoch == 18:\n",
    "# #         lr = lr / 2\n",
    "#     optimizer=torch.optim.SGD(net.parameters(), lr = lr)\n",
    "    print(epoch)\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    for batch_idx,(img,label) in enumerate(trainloader):\n",
    "        print(\"before\")\n",
    "        for p in net.parameters():\n",
    "            if p.requires_grad:\n",
    "                print(p.name, p.data)\n",
    "                break\n",
    "        inputs = img\n",
    "#         inputs.requires_grad_()\n",
    "#         inputs=inputs.to(device)\n",
    "        scores=net(inputs) \n",
    "#         label=label.to(device)\n",
    "        loss =  criterion( scores , label) \n",
    "        optimizer.zero_grad()   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error( scores.detach() , label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "        print(\"after\")\n",
    "        for p in net.parameters():\n",
    "            if p.requires_grad:\n",
    "                print(p.name, p.data)\n",
    "                break\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "#     if epoch % 10 == 0 : \n",
    "    if True:\n",
    "        print(' ')\n",
    "        print('epoch=',epoch, ' time=', elapsed_time,\n",
    "              ' loss=', total_loss , ' error=', total_error*100 ,'percent lr=', lr)\n",
    "        eval_on_test_set(valloader)\n",
    "#         state = {'net':net.state_dict(),'optimizer':optimizer.state_dict(),'epoch':epoch}\n",
    "        torch.save(net.state_dict(), model_dir + str(epoch) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_on_test_set(testloader)\n",
    "for i in range(0, 50, 10):\n",
    "    net.load_state_dict(torch.load(model_dir + str(i) + '.pth'))\n",
    "    net.eval()\n",
    "    eval_on_test_set(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(mlp , self).__init__()\n",
    "        self.layer1 = nn.Linear( input_size, hidden_size1 , bias=False)\n",
    "        self.layer2 = nn.Linear( hidden_size1, hidden_size2 , bias=False)\n",
    "        self.layer3 = nn.Linear( hidden_size2, output_size , bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "def get_error(scores , labels):\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    print(predicted_labels)\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches=indicator.sum()\n",
    "    \n",
    "    return 1-num_matches.float()/bs  \n",
    "\n",
    "def eval_on_test_set(loader):\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    for batch_idx,(img,label) in enumerate(loader):\n",
    "        img=img.view(img.size()[0],-1)\n",
    "        #img=img.to(device)\n",
    "        scores=net(img) \n",
    "        label=label.to(device) \n",
    "        error = get_error( scores , label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'test error  = ', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp(imgsize**2*3, imgsize*4, imgsize, 2)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "bs = 8\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=bs,shuffle=True,num_workers=0)\n",
    "valloader=torch.utils.data.DataLoader(valset,batch_size=bs,shuffle=False,num_workers=0)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=bs,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "epoch= 0  time= 13.031254053115845  loss= 4.2079029890605835  error= 32.02639751410404 percent lr= 0.05\n",
      "test error  =  32.2265625 percent\n",
      " \n",
      "epoch= 1  time= 32.6482880115509  loss= 0.6931471824645996  error= 31.49187768183424 percent lr= 0.05\n",
      "test error  =  32.2265625 percent\n",
      " \n",
      "epoch= 2  time= 53.30787396430969  loss= 0.6931471824645996  error= 31.47993311036789 percent lr= 0.05\n",
      "test error  =  32.2265625 percent\n",
      " \n",
      "epoch= 3  time= 73.26021409034729  loss= 0.6931471824645996  error= 31.47993311036789 percent lr= 0.05\n",
      "test error  =  32.2265625 percent\n",
      " \n",
      "epoch= 4  time= 93.52429795265198  loss= 0.6931471824645996  error= 31.48291925323448 percent lr= 0.05\n",
      "test error  =  32.2265625 percent\n",
      " \n",
      "epoch= 5  time= 114.07315993309021  loss= 0.6931471824645996  error= 31.485905396101067 percent lr= 0.05\n",
      "test error  =  32.2265625 percent\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-353a2895b2c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fused'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                  found_inf=found_inf)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m          found_inf=found_inf)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CS5242/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lr = 0.05\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = lr)\n",
    "for epoch in range(50):\n",
    "#     if epoch % 10 == 0 and epoch > 10: \n",
    "#         lr = lr / 1.5\n",
    "#     optimizer=torch.optim.SGD(net.parameters(), lr = lr)\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    net.train()\n",
    "    for batch_idx,(img,label) in enumerate(trainloader):\n",
    "        \n",
    "        inputs = img.view(img.size()[0],-1)\n",
    "        # inputs.requires_grad_()\n",
    "        # inputs=inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores=net(inputs) \n",
    "        # label=label.to(device)\n",
    "        loss =  criterion(scores , label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        running_loss += loss.item()\n",
    "        error = get_error(scores, label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "#     if epoch % 10 == 0 : \n",
    "    if True:\n",
    "        print(' ')\n",
    "        print('epoch=',epoch, ' time=', elapsed_time,\n",
    "              ' loss=', total_loss , ' error=', total_error*100 ,'percent lr=', lr)\n",
    "        eval_on_test_set(valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5242",
   "language": "python",
   "name": "cs5242"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
